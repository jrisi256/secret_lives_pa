{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize paths.\n",
    "csv_path = \"/home/joe/Documents/secret_lives_pa/output/pdf_download_list/\"\n",
    "\n",
    "# Intialize names for files.\n",
    "pdf_log_file_old = \"pdf_download_log.csv\"\n",
    "pdf_log_file_new = \"pdf_download_log_2.csv\"\n",
    "download_links_file = \"pdf_download_links.csv\"\n",
    "criminal_cases_file = \"criminal_pdf_links.csv.gz\"\n",
    "lt_cases_file = \"lt_pdf_links.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the old log file does not exist, create an empty log file and read initial starting links.\n",
    "if(not os.path.exists(csv_path + pdf_log_file_old)):\n",
    "\n",
    "    # Create empty log file.\n",
    "    csv_log_df = pd.DataFrame({\"file_name\": [], \"link\": [], \"status_code\":[]})\n",
    "    csv_log_df.to_csv(csv_path + pdf_log_file_old, index = False)\n",
    "\n",
    "    # Read in criminal cases.\n",
    "    criminal_cases_df = pd.read_csv(\n",
    "        csv_path + criminal_cases_file,\n",
    "        compression = \"gzip\",\n",
    "        dtype = {\"file_name\": str, \"link\": str, \"successfully_scraped\": bool},\n",
    "        nrows = 20\n",
    "    )\n",
    "    \n",
    "    # Read in landlord-tenant cases.\n",
    "    lt_cases_df = pd.read_csv(\n",
    "        csv_path + lt_cases_file,\n",
    "        compression = \"gzip\",\n",
    "        dtype = {\"file_name\": str, \"link\": str, \"successfully_scraped\": bool},\n",
    "        nrows = 20\n",
    "    )\n",
    "\n",
    "    # Combine cases.\n",
    "    cases_df = pd.concat([criminal_cases_df, lt_cases_df], axis = 0)\n",
    "    cases_df.to_csv(csv_path + download_links_file, index = False)\n",
    "\n",
    "# If the log file does exist, read in the log file and existing links.\n",
    "else:\n",
    "    csv_log_df = pd.read_csv(\n",
    "        csv_path + pdf_log_file_old,\n",
    "        dtype = {\"file_name\": str, \"link\": str, \"status_code\": float}\n",
    "    )\n",
    "\n",
    "    cases_df = pd.read_csv(\n",
    "        csv_path + download_links_file,\n",
    "        dtype = {\"file_name\": str, \"link\": str, \"successfully_scraped\": bool}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If it's not an empty log file, update our links using the results of the old log file, and create the new log file.\n",
    "if(len(csv_log_df) != 0):\n",
    "\n",
    "    # Update download links.\n",
    "    merged_df = pd.merge(cases_df, csv_log_df, on = [\"file_name\", \"link\"], how = \"outer\")\n",
    "    merged_df = merged_df.assign(successfully_scraped = np.where(merged_df[\"status_code\"] == 200, True, merged_df[\"successfully_scraped\"]))\n",
    "    merged_df = merged_df.drop(columns = [\"status_code\"])\n",
    "    merged_df.to_csv(csv_path + download_links_file, index = False)\n",
    "\n",
    "    # Create new empty log file.\n",
    "    csv_log_df_new = pd.DataFrame({\"file_name\": [], \"link\": [], \"status_code\":[]})\n",
    "    csv_log_df_new.to_csv(csv_path + pdf_log_file_new, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secret_lives_pa",
   "language": "python",
   "name": "secret_lives_pa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
