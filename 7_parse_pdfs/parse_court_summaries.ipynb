{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = [\n",
    "            \"adams\", \"allegheny\", \"armstrong\", \"beaver\", \"bedford\", \"berks\",\n",
    "            \"blair\", \"bradford\", \"bucks\", \"butler\", \"cambria\", \"cameron\",\n",
    "            \"carbon\", \"centre\", \"chester\", \"clarion\", \"clearfield\", \"clinton\",\n",
    "            \"columbia\", \"crawford\", \"cumberland\", \"dauphin\", \"delaware\", \"elk\",\n",
    "            \"erie\", \"fayette\", \"forest\", \"franklin\", \"fulton\", \"greene\",\n",
    "            \"huntingdon\", \"indiana\", \"jefferson\", \"juniata\", \"lackawanna\",\n",
    "            \"lancaster\", \"lawrence\", \"lebanon\", \"lehigh\", \"luzerne\", \"lycoming\",\n",
    "            \"mckean\", \"mercer\", \"mifflin\", \"monroe\", \"montgomery\", \"montour\",\n",
    "            \"northampton\", \"northumberla\", \"perry\", \"philadelphia\", \"pike\",\n",
    "            \"potter\", \"schuylkill\", \"snyder\", \"somerset\", \"sullivan\",\n",
    "            \"susquehanna\", \"tioga\", \"union\", \"venango\", \"warren\", \"washington\",\n",
    "            \"wayne\", \"westmoreland\", \"wyoming\", \"york\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"../output/pdf_sample/pdfs/cs_Montgomery_CP_46_CR_0009245_2005.pdf\"\n",
    "pdf = pdfplumber.open(pdf_path)\n",
    "\n",
    "# Concatenate all pages into one page, so to speak.\n",
    "pages = pdf.pages\n",
    "page_list = [page.extract_text(layout = True, x_density = 3.9, y_density = 13).split(\"\\n\") for page in pages]\n",
    "lines = [line for page in page_list for line in page]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_dict = {}\n",
    "\n",
    "# Beginning part of every court summary in court of common pleas has a block of text with person information.\n",
    "poi_start_index = [i for i, x in enumerate(lines) if \"DOB:\" in x][0]\n",
    "poi_end_index = [i for i,x in enumerate(lines) if \"closed\" in x.lower() or \"inactive\" in x.lower() or \"active\" in x.lower() or \"adjudicated\" in x.lower()][0]\n",
    "poi = lines[poi_start_index:poi_end_index]\n",
    "\n",
    "# Name, DOB, and Sex appear on the first line.\n",
    "poi_dict[\"name\"] = poi[0].split(\"DOB:\")[0].strip()\n",
    "poi_dict[\"dob\"] = poi[0].split(\"DOB:\")[1].split(\"Sex:\")[0].strip()\n",
    "poi_dict[\"sex\"] = poi[0].split(\"DOB:\")[1].split(\"Sex:\")[1].strip()\n",
    "\n",
    "# Location and Eye Color appear on the second line.\n",
    "poi_dict[\"home_location\"] = poi[1].split(\"Eyes:\")[0].strip().lower()\n",
    "poi_dict[\"eyes\"] = poi[1].split(\"Eyes:\")[1].strip()\n",
    "\n",
    "# Alias and hair color are on the third line, but alias is blank on this line.\n",
    "poi_dict[\"hair\"] = poi[2].split(\"Hair:\")[1].strip()\n",
    "\n",
    "# The first alias and race are on the fourth line.\n",
    "alias = poi[3].split(\"Race:\")[0].strip()\n",
    "poi_dict[\"race\"] = poi[3].split(\"Race:\")[1].strip()                          \n",
    "\n",
    "# The rest of the aliases are on subsequent lines.\n",
    "remainder_alias = poi[4:len(poi)]\n",
    "remainder_alias = [element.strip() for element in remainder_alias]\n",
    "remainder_alias.append(alias)\n",
    "poi_dict[\"alias\"] = remainder_alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sqncs_and_sntncs(s_idx, s_lines):\n",
    "    # Initialize starting values.\n",
    "    loop_through_sqncs_and_sntncs = True\n",
    "    seq_nr = -1\n",
    "    seq_nr_idx = \"seq_\" + str(seq_nr)\n",
    "    sentence_nr = -1\n",
    "    sentence_nr_idx = \"sentence_\" + str(sentence_nr)\n",
    "    seq_dict = {}\n",
    "\n",
    "    while(loop_through_sqncs_and_sntncs):\n",
    "\n",
    "        # If the current line is the last line, exit out of the function.\n",
    "        if(s_idx < len(s_lines)):\n",
    "            cur_s_line = s_lines[s_idx].lower().strip()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        # If the current line is a new set of case statuses, or a new county, function is completed.\n",
    "        if(((\"closed\" == cur_s_line or \"inactive\" == cur_s_line or \"active\" == cur_s_line or \"adjudicated\" == cur_s_line or cur_s_line in counties or \"proc status: \" in cur_s_line) and \"continued\" not in cur_s_line)):\n",
    "            break\n",
    "        # When we encounter ยง, it marks the beginning of a new sequence.\n",
    "        elif(\"ยง\" in cur_s_line):\n",
    "            # Reset the sentence counter because we are on a new sequence of charges.\n",
    "            sentence_nr = -1\n",
    "            sentence_nr_idx = \"sentence_\" + str(sentence_nr)\n",
    "            \n",
    "            seq_nr += 1\n",
    "            seq_nr_idx = \"seq_\" + str(seq_nr)\n",
    "            seq_dict[seq_nr_idx] = {}\n",
    "\n",
    "            # You can think of the PDF as a fixed-width data table. Hopefully, each of these values is always contained within these lengths.\n",
    "            seq_dict[seq_nr_idx][\"seq_num\"] = cur_s_line[:11].strip()\n",
    "            seq_dict[seq_nr_idx][\"statute\"] = cur_s_line[11:48].strip()\n",
    "            seq_dict[seq_nr_idx][\"grade\"] = cur_s_line[48:54].strip()\n",
    "            seq_dict[seq_nr_idx][\"description\"] = cur_s_line[54:95].strip()\n",
    "            seq_dict[seq_nr_idx][\"disposition\"] = cur_s_line[95:].strip()\n",
    "\n",
    "        # When we encounter \"min:\" or \"max:\", we begin capturing the sentenced punishments.\n",
    "        elif(\"min:\" in cur_s_line or \"max:\" in cur_s_line or re.search(r\"\\d{2}/\\d{2}/\\d{4}\", cur_s_line)):\n",
    "            sentence_nr += 1\n",
    "            sentence_nr_idx = \"sentence_\" + str(sentence_nr)\n",
    "            seq_dict[seq_nr_idx][sentence_nr_idx] = {}\n",
    "\n",
    "            # You can think of the PDF as a fixed-width data table. Hopefully, each of these values is always contained within these lengths.\n",
    "            seq_dict[seq_nr_idx][sentence_nr_idx][\"sentence_date\"] = cur_s_line[:17].strip()\n",
    "            seq_dict[seq_nr_idx][sentence_nr_idx][\"sentence_type\"] = cur_s_line[17:43].strip()\n",
    "            seq_dict[seq_nr_idx][sentence_nr_idx][\"program_period\"] = cur_s_line[43:74].strip()\n",
    "            seq_dict[seq_nr_idx][sentence_nr_idx][\"sentence_length\"] = cur_s_line[74:].strip()\n",
    "\n",
    "        # Move on to the next line.=\n",
    "        s_idx += 1\n",
    "\n",
    "    return seq_dict, s_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_closed_cases(c_idx, c_lines):\n",
    "    # Initialize starting values.\n",
    "    loop_through_closed_cases = True\n",
    "    closed_dict = {}\n",
    "    case_nr = -1\n",
    "    case_nr_idx = \"case_\" + str(case_nr)\n",
    "    line_increment_c = c_idx\n",
    "    \n",
    "    while(loop_through_closed_cases):\n",
    "        \n",
    "        # If we are on the last line of the PDF, we have finished all closed cases.\n",
    "        if(c_idx < len(c_lines)):\n",
    "            cur_c_line = c_lines[c_idx].lower().strip()\n",
    "        else:\n",
    "            loop_through_closed_cases = False\n",
    "            continue\n",
    "\n",
    "        # If the current line has a case status, we have finished all closed cases.\n",
    "        if((\"inactive\" == cur_c_line or \"active\" == cur_c_line or \"adjudicated\" == cur_c_line) and \"continued\" not in cur_c_line):\n",
    "            loop_through_closed_cases = False\n",
    "        # Check if the current line is a new county.\n",
    "        elif(cur_c_line in counties):\n",
    "            line_increment_c += 1\n",
    "            county = cur_c_line\n",
    "        # If we are not on a new county or new case status, then we are on a new case.\n",
    "        # 1st line: Docket Number, Proc. Status, DC Number, and OTN Number.\n",
    "        # 2nd line: Arrest date, disposition date, and disposition judge.\n",
    "        # 3rd line: Defense attorney\n",
    "        elif(\"proc status: \" in cur_c_line):\n",
    "            # If the previous line has continued, we need to investigate.\n",
    "            if(\"continued\" in c_lines[c_idx -1].lower().strip()):\n",
    "                # Check and see if the current docket # equals the docket # in our dictionary. If so, we can skip this line since we already collected this info.\n",
    "                # If the current docket # does not equal the docket # in our dictionary, it is new case whose data we need to collect.\n",
    "                # Also, if this is the first docket # for this set of case statues, then this is also obviously a new case.\n",
    "                cur_line_docket_number = cur_c_line.split(\"proc status:\")[0].strip()\n",
    "                if(case_nr != -1 and cur_line_docket_number == closed_dict[case_nr_idx][\"docket_number\"]):\n",
    "                    line_increment_c += 1\n",
    "                    c_idx = line_increment_c\n",
    "                    continue\n",
    "                \n",
    "            line_increment_c += 1\n",
    "            case_nr += 1\n",
    "            case_nr_idx = \"case_\" + str(case_nr)\n",
    "            closed_dict[case_nr_idx] = {}\n",
    "            \n",
    "            closed_dict[case_nr_idx][\"county\"] = county\n",
    "            closed_dict[case_nr_idx][\"docket_number\"] = cur_c_line.split(\"proc status:\")[0].strip()\n",
    "            closed_dict[case_nr_idx][\"proc_status\"] = cur_c_line.split(\"proc status:\")[1].split(\"dc no:\")[0].strip().lower()\n",
    "            closed_dict[case_nr_idx][\"dc_nr\"] = cur_c_line.split(\"proc status:\")[1].split(\"dc no:\")[1].split(\"otn:\")[0].strip().lower()\n",
    "            closed_dict[case_nr_idx][\"otn_nr\"] = cur_c_line.split(\"proc status:\")[1].split(\"dc no:\")[1].split(\"otn:\")[1].strip().lower()\n",
    "        elif(\"arrest dt: \" in cur_c_line):\n",
    "            line_increment_c += 1\n",
    "            closed_dict[case_nr_idx][\"arrest_date\"] = cur_c_line.split(\"arrest dt:\")[1].split(\"disp date:\")[0].strip()\n",
    "            closed_dict[case_nr_idx][\"disp_date\"] = cur_c_line.split(\"arrest dt:\")[1].split(\"disp date:\")[1].split(\"disp judge:\")[0].strip()\n",
    "            closed_dict[case_nr_idx][\"disp_judge\"] = cur_c_line.split(\"arrest dt:\")[1].split(\"disp date:\")[1].split(\"disp judge:\")[1].strip()\n",
    "        elif(\"def atty:\" in cur_c_line):\n",
    "            line_increment_c += 1\n",
    "            closed_dict[case_nr_idx][\"def_attorney\"] = cur_c_line.split(\"def atty:\")[1].strip()\n",
    "        # When we encounter ยง, it marks the beginning of a new sequence.\n",
    "        elif(\"ยง\" in cur_c_line):\n",
    "            result_tuple = extract_sqncs_and_sntncs(c_idx, c_lines)\n",
    "            sequence_dict, line_increment_c = result_tuple\n",
    "            closed_dict[case_nr_idx].update(sequence_dict)\n",
    "        # If the line does not contain any of the above characters, it's a junk line, and we can skip it.\n",
    "        else:\n",
    "            line_increment_c += 1\n",
    "\n",
    "        c_idx = line_increment_c\n",
    "\n",
    "    return closed_dict, c_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_inactive_active_cases(ia_idx, ia_lines):\n",
    "    # Initialize starting values.\n",
    "    loop_through_ia_cases = True\n",
    "    ia_dict = {}\n",
    "    case_nr = -1\n",
    "    case_nr_idx = \"case_\" + str(case_nr)\n",
    "    line_increment_ia = ia_idx\n",
    "\n",
    "    while(loop_through_ia_cases):\n",
    "        # If we are on the last line of the PDF, we have finished all active/inactive/adjudicated cases.\n",
    "        if(ia_idx < len(ia_lines)):\n",
    "            cur_ia_line = ia_lines[ia_idx].lower().strip()\n",
    "        else:\n",
    "            loop_through_ia_cases = False\n",
    "            continue\n",
    "        # If the current line has a case status, we have finished all active/inactive/adjudicated cases.\n",
    "        if(((\"closed\" == cur_ia_line or \"inactive\" == cur_ia_line or \"active\" == cur_ia_line or \"adjudicated\" == cur_ia_line) and \"continued\" not in cur_ia_line)):\n",
    "            loop_through_ia_cases = False\n",
    "        # Check if the current line is a new county.\n",
    "        elif(cur_ia_line in counties):\n",
    "            line_increment_ia += 1\n",
    "            county = cur_ia_line\n",
    "        # If we are not on a new county or new case status, then we are on a new case.\n",
    "        # 1st line: Docket Number, Proc. Status, DC Number, and OTN Number.\n",
    "        # 2nd line: Arrest date, trial date, legacy number.\n",
    "        # 3rd line: Last action, last action date, last action room.\n",
    "        # 4th line: Next action, next action date, next action room.\n",
    "        # Occasionally, the defense attorney will also be listed (in between the 2nd and 3rd line).\n",
    "        # Also occasionally, we can get a disposition date and disposition judge on the 5th line.\n",
    "        elif(\"proc status: \" in cur_ia_line):\n",
    "            # If the previous line has continued, we need to investigate.\n",
    "            if(\"continued\" in ia_lines[ia_idx - 1].lower().strip()):\n",
    "                # Check and see if the current docket # equals the docket # in our dictionary. If so, we can skip this line since we already collected this info.\n",
    "                # If the current docket # does not equal the docket # in our dictionary, it is new case whose data we need to collect.\n",
    "                # Also, if this is the first docket # for this set of case statues, then this is also obviously a new case.\n",
    "                cur_line_docket_number = cur_ia_line.split(\"proc status:\")[0].strip()\n",
    "                if(case_nr != -1 and cur_line_docket_number == ia_dict[case_nr_idx][\"docket_number\"]):\n",
    "                    line_increment_ia += 1\n",
    "                    ia_idx = line_increment_ia\n",
    "                    continue\n",
    "                \n",
    "            line_increment_ia += 1\n",
    "            case_nr += 1\n",
    "            case_nr_idx = \"case_\" + str(case_nr)\n",
    "            ia_dict[case_nr_idx] = {}\n",
    "            \n",
    "            ia_dict[case_nr_idx][\"county\"] = county\n",
    "            ia_dict[case_nr_idx][\"docket_number\"] = cur_ia_line.split(\"proc status:\")[0].strip()\n",
    "            ia_dict[case_nr_idx][\"proc_status\"] = cur_ia_line.split(\"proc status:\")[1].split(\"dc no:\")[0].strip()\n",
    "            ia_dict[case_nr_idx][\"dc_nr\"] = cur_ia_line.split(\"proc status:\")[1].split(\"dc no:\")[1].split(\"otn:\")[0].strip()\n",
    "            ia_dict[case_nr_idx][\"otn_nr\"] = cur_ia_line.split(\"proc status:\")[1].split(\"dc no:\")[1].split(\"otn:\")[1].strip()\n",
    "        elif(\"arrest dt: \" in cur_ia_line):\n",
    "            line_increment_ia += 1\n",
    "            ia_dict[case_nr_idx][\"arrest_date\"] = cur_ia_line.split(\"arrest dt:\")[1].split(\"trial dt:\")[0].strip()\n",
    "            ia_dict[case_nr_idx][\"trial_date\"] = cur_ia_line.split(\"trial dt:\")[1].split(\"legacy no:\")[0].strip()\n",
    "            ia_dict[case_nr_idx][\"legacy_number\"] = cur_ia_line.split(\"trial dt:\")[1].split(\"legacy no:\")[1].strip()\n",
    "        elif(\"last action: \" in cur_ia_line):\n",
    "            line_increment_ia += 1\n",
    "            ia_dict[case_nr_idx][\"last_action\"] = cur_ia_line.split(\"last action:\")[1].split(\"last action date:\")[0].strip()\n",
    "            ia_dict[case_nr_idx][\"last_action_date\"] = cur_ia_line.split(\"last action:\")[1].split(\"last action date:\")[1].split(\"last action room:\")[0].strip()\n",
    "            ia_dict[case_nr_idx][\"last_action_room\"] = cur_ia_line.split(\"last action:\")[1].split(\"last action date:\")[1].split(\"last action room:\")[1].strip()\n",
    "        elif(\"next action: \" in cur_ia_line):\n",
    "            line_increment_ia += 1\n",
    "            ia_dict[case_nr_idx][\"next_action\"] = cur_ia_line.split(\"next action:\")[1].split(\"next action date:\")[0].strip()\n",
    "            ia_dict[case_nr_idx][\"next_action_date\"] = cur_ia_line.split(\"next action:\")[1].split(\"next action date:\")[1].split(\"next action room:\")[0].strip()\n",
    "            ia_dict[case_nr_idx][\"next_action_room\"] = cur_ia_line.split(\"next action:\")[1].split(\"next action date:\")[1].split(\"next action room:\")[1].strip()\n",
    "        elif(\"def atty: \" in cur_ia_line):\n",
    "            line_increment_ia += 1\n",
    "            ia_dict[case_nr_idx][\"def_attorney\"] = cur_ia_line.split(\"def atty:\")[1].strip()\n",
    "        # When we encounter ยง, it marks the beginning of a new sequence.\n",
    "        elif(\"ยง\" in cur_ia_line):\n",
    "            result_tuple = extract_sqncs_and_sntncs(ia_idx, ia_lines)\n",
    "            sequence_dict, line_increment_ia = result_tuple\n",
    "            ia_dict[case_nr_idx].update(sequence_dict)\n",
    "        elif(\"disp date:\" in cur_ia_line):\n",
    "            line_increment_ia += 1\n",
    "            ia_dict[case_nr_idx][\"disp_date\"] = cur_ia_line.split(\"disp date:\")[1].split(\"disp judge:\")[0].strip()\n",
    "            ia_dict[case_nr_idx][\"disp_judge\"] = cur_ia_line.split(\"disp date:\")[1].split(\"disp judge:\")[1].strip()\n",
    "        # If the line does not contain any of the above characters, it's a junk line, and we can skip it.\n",
    "        else:\n",
    "            line_increment_ia += 1\n",
    "\n",
    "        ia_idx = line_increment_ia\n",
    "\n",
    "    return ia_dict, ia_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_line_index = poi_end_index\n",
    "cs_dict = {}\n",
    "\n",
    "# Loop through the rest of the lines and capture information about an individual's criminal history.\n",
    "while(current_line_index < len(lines)):\n",
    "    cur_line = lines[current_line_index].lower().strip()\n",
    "    new_line_index = \"\"\n",
    "    \n",
    "    # Check if the current line is a new set of case (statuses).\n",
    "    if((\"closed\" in cur_line or \"inactive\" in cur_line or \"active\" in cur_line or \"adjudicated\" in cur_line) and \"continued\" not in cur_line):\n",
    "        case_status = cur_line\n",
    "        cs_dict[case_status] = {}\n",
    "\n",
    "        # Increment the index by 1 because we want to start parsing the line following the case status line.\n",
    "        if(case_status == \"closed\"):\n",
    "            result_tuple = extract_closed_cases(current_line_index + 1, lines)\n",
    "        elif(case_status == \"inactive\" or case_status == \"active\" or case_status == \"adjudicated\"):\n",
    "            result_tuple = extract_inactive_active_cases(current_line_index + 1, lines)\n",
    "\n",
    "        cs_dict[case_status], new_line_index = result_tuple\n",
    "    \n",
    "    current_line_index = new_line_index\n",
    "\n",
    "poi_dict.update(cs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"test.json\"\n",
    "\n",
    "with open(filename, \"w\") as json_file:\n",
    "    json.dump(poi_dict, json_file, indent = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secret_lives_pa",
   "language": "python",
   "name": "secret_lives_pa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
