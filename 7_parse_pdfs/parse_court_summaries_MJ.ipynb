{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = [\n",
    "            \"adams\", \"allegheny\", \"armstrong\", \"beaver\", \"bedford\", \"berks\",\n",
    "            \"blair\", \"bradford\", \"bucks\", \"butler\", \"cambria\", \"cameron\",\n",
    "            \"carbon\", \"centre\", \"chester\", \"clarion\", \"clearfield\", \"clinton\",\n",
    "            \"columbia\", \"crawford\", \"cumberland\", \"dauphin\", \"delaware\", \"elk\",\n",
    "            \"erie\", \"fayette\", \"forest\", \"franklin\", \"fulton\", \"greene\",\n",
    "            \"huntingdon\", \"indiana\", \"jefferson\", \"juniata\", \"lackawanna\",\n",
    "            \"lancaster\", \"lawrence\", \"lebanon\", \"lehigh\", \"luzerne\", \"lycoming\",\n",
    "            \"mckean\", \"mercer\", \"mifflin\", \"monroe\", \"montgomery\", \"montour\",\n",
    "            \"northampton\", \"northumberla\", \"perry\", \"philadelphia\", \"pike\",\n",
    "            \"potter\", \"schuylkill\", \"snyder\", \"somerset\", \"sullivan\",\n",
    "            \"susquehanna\", \"tioga\", \"union\", \"venango\", \"warren\", \"washington\",\n",
    "            \"wayne\", \"westmoreland\", \"wyoming\", \"york\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pdf_path = \"../output/pdf_sample/pdfs/cs_Allegheny_MJ_05003_CR_0000302_2014.pdf\"\n",
    "#pdf_path = \"../output/pdf_sample/pdfs/cs_Allegheny_MJ_05003_CR_0002676_2014.pdf\"\n",
    "#pdf_path = \"../output/pdf_sample/pdfs/cs_Blair_MJ_24102_CR_0000085_2019.pdf\"\n",
    "#pdf_path = \"../output/pdf_sample/pdfs/cs_Blair_MJ_24103_CR_0000555_2005.pdf\"\n",
    "#pdf_path = \"../output/pdf_sample/pdfs/cs_Dauphin_MJ_12201_CR_0000565_2023.pdf\"\n",
    "#pdf_path = \"../output/pdf_sample/pdfs/cs_Dauphin_MJ_12205_CR_0000378_2023.pdf\"\n",
    "#pdf_path = \"../output/pdf_sample/pdfs/cs_Centre_MJ_49101_CR_0000384_2014.pdf\"\n",
    "#pdf_path = \"../output/pdf_sample/pdfs/cs_Blair_MJ_24102_CR_0000562_2023.pdf\"\n",
    "#pdf_path = \"../output/pdf_sample/pdfs/cs_Blair_MJ_24103_CR_0000034_2019.pdf\"\n",
    "#pdf_path = \"../output/pdf_sample/pdfs/cs_Blair_MJ_24302_CR_0000197_2019.pdf\"\n",
    "#pdf_path = \"../output/pdf_sample/pdfs/cs_Blair_MJ_24303_CR_0000025_2019.pdf\"\n",
    "pdf_path = \"../output/pdf_sample/pdfs/cs_Allegheny_MJ_05247_CR_0000674_2023.pdf\"\n",
    "pdf = pdfplumber.open(pdf_path)\n",
    "\n",
    "# Concatenate all pages into one page, so to speak.\n",
    "pages = pdf.pages\n",
    "page_list = [page.extract_text(layout = True, x_density = 3.9, y_density = 13).split(\"\\n\") for page in pages]\n",
    "lines = [line for page in page_list for line in page]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_dict = {}\n",
    "\n",
    "# Beginning part of every court summary in court of common pleas has a block of text with person information.\n",
    "# Organizations do not have date of birth so we need another way to identify the beginning of the POI information.\n",
    "try:\n",
    "    poi_start_index = [i for i, x in enumerate(lines) if \"DOB:\" in x][0]\n",
    "except Exception as e:\n",
    "    # Search through the lines until we come to the first line which does not contain the key phrases and is not an empty line.\n",
    "    for i, line in enumerate(lines):\n",
    "        if(re.search(\"magisterial\\s+district\\s+court\", line.lower()) is None and re.search(\"public\\s+court\\s+summary\", line.lower()) is None and line.strip() != \"\"):\n",
    "            poi_start_index = i\n",
    "            break\n",
    "    \n",
    "poi_end_index = [i for i,x in enumerate(lines) if \"court:\" in x.lower()][0]\n",
    "poi = lines[poi_start_index:poi_end_index]\n",
    "\n",
    "# Name, DOB, and Sex appear on the first line. Very rarely they do not (such as when it's an organization who is the defendant).\n",
    "if(\"DOB:\" in poi[0] and \"Sex:\" in poi[0]):\n",
    "    poi_dict[\"name\"] = poi[0].split(\"DOB:\")[0].strip()\n",
    "    poi_dict[\"dob\"] = poi[0].split(\"DOB:\")[1].split(\"Sex:\")[0].strip()\n",
    "    poi_dict[\"sex\"] = poi[0].split(\"DOB:\")[1].split(\"Sex:\")[1].strip()\n",
    "# If DOB and sex do not appear, the name should still appear.\n",
    "else:\n",
    "    poi_dict[\"name\"] = poi[0].strip()\n",
    "\n",
    "# Location and Eye Color appear on the second line unless it's an organization (like above).\n",
    "if(\"Eyes:\" in poi[1]):\n",
    "    poi_dict[\"home_location\"] = poi[1].split(\"Eyes:\")[0].strip().lower()\n",
    "    poi_dict[\"eyes\"] = poi[1].split(\"Eyes:\")[1].strip()\n",
    "# If eye color does not appear, the home location still should.\n",
    "else:\n",
    "    poi_dict[\"home_location\"] = poi[1].strip()\n",
    "\n",
    "# For organizations, the personal information will only be 3 lines.\n",
    "if(len(poi) > 3):\n",
    "    # Hair color is on the third line.\n",
    "    poi_dict[\"hair\"] = poi[2].split(\"Hair:\")[1].strip()\n",
    "\n",
    "    # Race is on the fourth line.\n",
    "    poi_dict[\"race\"] = poi[3].split(\"Race:\")[1].strip()\n",
    "\n",
    "    # On the fifth line, if the person has an alias, their aliases will be listed here.\n",
    "    # If they do not have any aliases, the PDF immediately starts the criminal history.\n",
    "    poi_dict[\"alias\"] = \"\"\n",
    "    if(len(poi) > 4):\n",
    "        poi_dict[\"alias\"] = poi[4].split(\"Aliases:\")[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_punishment(p_idx, p_lines):\n",
    "    # Initialize starting values\n",
    "    loop_through_punishment = True\n",
    "    punishment_nr = -1\n",
    "    punishment_nr_idx = \"punishment_nr_\" + str(punishment_nr)\n",
    "    punishment_dict = {}\n",
    "\n",
    "    while(loop_through_punishment):\n",
    "        # If the current line is the last line, exit out of the function.\n",
    "        if(p_idx < len(p_lines)):\n",
    "            cur_p_line = p_lines[p_idx].lower()\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        # If the current line has processing status, court, county, statewide, otn:, otn/lotn:, or a case status, then it is a new case.\n",
    "        # This means we've reached the end of punishments.\n",
    "        if(\"processing status:\" in cur_p_line or \"court:\" in cur_p_line or \"county:\" in cur_p_line or \"statewide\" in cur_p_line or \"otn:\" in cur_p_line or \"otn/lotn:\" in cur_p_line or cur_p_line in counties or cur_p_line in [\"active\", \"inactive\", \"closed\", \"adjudicated\"]):\n",
    "            break\n",
    "        # If the line is only whitespace, if it has reached the bottom-of-the-page text, or it has demographic information, ignore it.\n",
    "        elif(cur_p_line.strip() == \"\" or \"printed:\" in cur_p_line or re.search(\"recent\\s+entries\\s+made\\s+in\\s+the\", cur_p_line) or re.search(\"system\\s+of\\s+the\\s+commonwealth\\s+of\", cur_p_line) or re.search(\"should\\s+not\\s+be\\s+used\\s+in\\s+place\", cur_p_line) or re.search(\"employers\\s+who\\s+do\\s+not\\s+comply\", cur_p_line) or re.search(\"may\\s+be\\s+subject\\s+to\\s+civil\", cur_p_line) or re.search(\"please\\s+note\\s+that\\s+if\\s+the\", cur_p_line) or re.search(\"court\\s+case\\s+management\\s+system\\s+for\\s+this\\s+offense\", cur_p_line) or re.search(\"is\\s+charged\\s+in\\s+order\\s+to\", cur_p_line) or re.search(\"public\\s+court\\s+summary\", cur_p_line) or \"dob:\" in cur_p_line or \"eyes:\" in cur_p_line or \" hair:\" in cur_p_line or \"race:\" in cur_p_line):\n",
    "            p_idx += 1\n",
    "            continue\n",
    "        # If we have not hit a new case, then the line is a punishment.\n",
    "        else:\n",
    "            program_type = cur_p_line[:55].strip()\n",
    "            sentence_date = cur_p_line[55:88].strip()\n",
    "            sentence_length = cur_p_line[88:137].strip()\n",
    "            program_period = cur_p_line[137:].strip()\n",
    "\n",
    "            # This indicates the punishment line is an overflow line that is still describing the previous punishment's sentence length.\n",
    "            if(program_type == \"\" and sentence_date == \"\" and program_period == \"\" and punishment_nr_idx != -1):\n",
    "                punishment_dict[punishment_nr_idx][\"sentence_length\"] = punishment_dict[punishment_nr_idx][\"sentence_length\"] + \" \" + sentence_length\n",
    "            # This indicates the punishment line is an overflow line that is still describing the previous punishment's program type.\n",
    "            elif(sentence_length == \"\" and sentence_date == \"\" and program_period == \"\" and punishment_nr_idx != -1):\n",
    "                punishment_dict[punishment_nr_idx][\"program_type\"] = punishment_dict[punishment_nr_idx][\"program_type\"] + \" \" + program_type\n",
    "            else:\n",
    "                punishment_nr += 1\n",
    "                punishment_nr_idx = \"punishment_nr_\" + str(punishment_nr)\n",
    "                punishment_dict[punishment_nr_idx] = {}\n",
    "\n",
    "                punishment_dict[punishment_nr_idx][\"program_type\"] = program_type\n",
    "                punishment_dict[punishment_nr_idx][\"sentence_date\"] = sentence_date\n",
    "                punishment_dict[punishment_nr_idx][\"sentence_length\"] = sentence_length\n",
    "                punishment_dict[punishment_nr_idx][\"program_period\"] = program_period\n",
    "\n",
    "        # Move on to the next line.\n",
    "        p_idx += 1\n",
    "\n",
    "    return punishment_dict, p_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cases(c_idx, c_lines):\n",
    "    # Set initial values.\n",
    "    case_nr = -1\n",
    "    case_nr_idx = \"case_nr_\" + str(case_nr)\n",
    "    charge_nr = -1\n",
    "    charge_nr_idx = \"charge_nr_\" + str(charge_nr)\n",
    "    punishment_nr = -1\n",
    "    punishment_nr_idx = \"punishment_nr_\" + str(punishment_nr)\n",
    "\n",
    "    loop_through_cases = True\n",
    "    statewide_flag = False\n",
    "    current_court_county = \"\"\n",
    "    current_case_status = \"\"\n",
    "\n",
    "    line_increment_c = c_idx\n",
    "    case_dict = {}\n",
    "\n",
    "    while(loop_through_cases):\n",
    "        # If the current line is the last line, exit out of the function.\n",
    "        if(c_idx < len(c_lines)):\n",
    "            cur_c_line = c_lines[c_idx].lower().strip()\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        # Set the court/county for this set of cases.\n",
    "        if(\"court:\" in cur_c_line or \"county:\" in cur_c_line or cur_c_line in counties):\n",
    "            # Clean up the line.\n",
    "            if(\"court:\" in cur_c_line):\n",
    "                new_court_county = cur_c_line.split(\"court:\")[1].strip()\n",
    "            elif(\"county:\" in cur_c_line):\n",
    "                new_court_county = cur_c_line.split(\"county:\")[1].strip()\n",
    "            elif(cur_c_line in counties):\n",
    "                new_court_county = cur_c_line\n",
    "\n",
    "            # Check if the new county/court is different from our current county/court. If it is, update the current court/county.\n",
    "            if(new_court_county != current_court_county):\n",
    "                current_court_county = new_court_county\n",
    "\n",
    "        # Set the case status for this set of cases and check that it is different from the previous case status.\n",
    "        if((\"closed\" == cur_c_line or \"inactive\" == cur_c_line or \"active\" == cur_c_line or \"adjudicated\" == cur_c_line) and cur_c_line != current_case_status):\n",
    "            current_case_status = cur_c_line\n",
    "\n",
    "        # I believe statewide cases are always at the end of the PDF so once this is turned on, it stays on.\n",
    "        # I.e., all subsequent cases will always be statewide.\n",
    "        if(\"statewide\" == cur_c_line):\n",
    "            statewide_flag = True\n",
    "\n",
    "        # When we encounter processing status/otn, we are on a new case.\n",
    "        # 1st line is Docket number, processing status, and OTN.\n",
    "        # 2nd line is arrest date, processing location, and disposition event date.\n",
    "        # 3rd line is last action and last action date.\n",
    "        # 4th line is next action and next action date.\n",
    "        # 5th line (optional) is bail type, bail amount, and bail status.\n",
    "        # After that, each subsequent line is a prior charge.\n",
    "        if(\"processing status:\" in cur_c_line or \"otn:\" in cur_c_line or \"otn/lotn:\" in cur_c_line):\n",
    "            line_increment_c += 1\n",
    "\n",
    "            case_nr += 1\n",
    "            case_nr_idx = \"case_\" + str(case_nr)\n",
    "            case_dict[case_nr_idx] = {}\n",
    "\n",
    "            charge_nr = -1\n",
    "            charge_nr_idx = \"charge_nr_\" + str(charge_nr)\n",
    "\n",
    "            case_dict[case_nr_idx][\"court_or_county\"] = current_court_county\n",
    "            case_dict[case_nr_idx][\"case_status\"] = current_case_status\n",
    "            case_dict[case_nr_idx][\"statewide\"] = statewide_flag\n",
    "            \n",
    "            # Sometimes a case may not have a processing status.\n",
    "            if(\"processing status:\" not in cur_c_line):\n",
    "                if(\"otn/lotn:\" in cur_c_line):\n",
    "                    case_dict[case_nr_idx][\"docket_number\"] = cur_c_line.split(\"otn/lotn:\")[0].strip().lower()\n",
    "                    case_dict[case_nr_idx][\"otn_lotn\"] = cur_c_line.split(\"otn/lotn:\")[1].strip().lower()\n",
    "                elif(\"otn:\" in cur_c_line):\n",
    "                    case_dict[case_nr_idx][\"docket_number\"] = cur_c_line.split(\"otn:\")[0].strip().lower()\n",
    "                    case_dict[case_nr_idx][\"otn\"] = cur_c_line.split(\"otn:\")[1].strip().lower()\n",
    "            else:\n",
    "                if(\"otn/lotn:\" in cur_c_line):\n",
    "                    case_dict[case_nr_idx][\"docket_number\"] = cur_c_line.split(\"processing status:\")[0].strip()\n",
    "                    case_dict[case_nr_idx][\"proc_status\"] = cur_c_line.split(\"processing status:\")[1].split(\"otn/lotn:\")[0].strip().lower()\n",
    "                    case_dict[case_nr_idx][\"otn_lotn\"] = cur_c_line.split(\"processing status:\")[1].split(\"otn/lotn:\")[1].strip().lower()\n",
    "                elif(\"otn:\" in cur_c_line):\n",
    "                    case_dict[case_nr_idx][\"docket_number\"] = cur_c_line.split(\"processing status:\")[0].strip()\n",
    "                    case_dict[case_nr_idx][\"proc_status\"] = cur_c_line.split(\"processing status:\")[1].split(\"otn:\")[0].strip().lower()\n",
    "                    case_dict[case_nr_idx][\"otn\"] = cur_c_line.split(\"processing status:\")[1].split(\"otn:\")[1].strip().lower()\n",
    "        elif(\"arrest date:\" in cur_c_line):\n",
    "            line_increment_c += 1\n",
    "            case_dict[case_nr_idx][\"arrest_date\"] = cur_c_line[:42].split(\"arrest date:\")[1].strip().lower()\n",
    "            case_dict[case_nr_idx][\"case_location\"] = cur_c_line[42:88].strip().lower()\n",
    "            case_dict[case_nr_idx][\"disp_event_date\"] = cur_c_line[88:].split(\"disp. event date:\")[1].strip().lower()\n",
    "        elif(\"last action:\" in cur_c_line):\n",
    "            line_increment_c += 1\n",
    "            case_dict[case_nr_idx][\"last_action\"] = cur_c_line.split(\"last action:\")[1].split(\"last action date:\")[0].strip().lower()\n",
    "            case_dict[case_nr_idx][\"last_action_date\"] = cur_c_line.split(\"last action:\")[1].split(\"last action date:\")[1].strip().lower()\n",
    "        elif(\"next action:\" in cur_c_line):\n",
    "            line_increment_c += 1\n",
    "            case_dict[case_nr_idx][\"next_action\"] = cur_c_line.split(\"next action:\")[1].split(\"next action date:\")[0].strip().lower()\n",
    "            case_dict[case_nr_idx][\"next_action_date\"] = cur_c_line.split(\"next action:\")[1].split(\"next action date:\")[1].strip().lower()\n",
    "        elif(\"bail type:\" in cur_c_line):\n",
    "            line_increment_c += 1\n",
    "            case_dict[case_nr_idx][\"bail_type\"] = cur_c_line.split(\"bail type:\")[1].split(\"bail amount:\")[0].strip().lower()\n",
    "            case_dict[case_nr_idx][\"bail_amount\"] = cur_c_line.split(\"bail type:\")[1].split(\"bail amount:\")[1].split(\"bail status:\")[0].strip().lower()\n",
    "            case_dict[case_nr_idx][\"bail_status\"] = cur_c_line.split(\"bail type:\")[1].split(\"bail amount:\")[1].split(\"bail status:\")[1].strip().lower()\n",
    "        elif(\"ยง\" in cur_c_line):\n",
    "            line_increment_c += 1\n",
    "            charge_nr += 1\n",
    "            charge_nr_idx = \"charge_nr_\" + str(charge_nr)\n",
    "            case_dict[case_nr_idx][charge_nr_idx] = {}\n",
    "\n",
    "            case_dict[case_nr_idx][charge_nr_idx][\"statute\"] = cur_c_line[:31].strip()\n",
    "            case_dict[case_nr_idx][charge_nr_idx][\"grade\"] = cur_c_line[31:42].strip()\n",
    "            case_dict[case_nr_idx][charge_nr_idx][\"description\"] = cur_c_line[42:88].strip()\n",
    "            case_dict[case_nr_idx][charge_nr_idx][\"disposition\"] = cur_c_line[88:130].strip()\n",
    "            case_dict[case_nr_idx][charge_nr_idx][\"counts\"] = cur_c_line[130:].strip()\n",
    "        elif(re.search(\"program\\s+type\", cur_c_line)):\n",
    "            # Start at the next line because that is whre the punishment starts.\n",
    "            punishment_tuple = extract_punishment(c_idx + 1, c_lines)\n",
    "            punishment_dict, line_increment_c = punishment_tuple\n",
    "            case_dict[case_nr_idx].update(punishment_dict)\n",
    "        # If the line does not contain any of the above characters, it's a junk line, and we can skip it.\n",
    "        else:\n",
    "            line_increment_c += 1\n",
    "\n",
    "        c_idx = line_increment_c\n",
    "    \n",
    "    return(case_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_line_index = poi_end_index\n",
    "case_dict_all = extract_cases(current_line_index, lines)\n",
    "poi_dict.update(case_dict_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"test.json\"\n",
    "\n",
    "with open(filename, \"w\") as json_file:\n",
    "    json.dump(poi_dict, json_file, indent = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secret_lives_pa_virtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
